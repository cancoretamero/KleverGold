#!/usr/bin/env python3
"""
Train a super model combining price technical indicators and aggregated news features
for gold price prediction.

This script loads gold price data (xauusd_ohlc_clean.csv) from the public/data directory and
computes technical indicators such as moving averages, exponential moving averages,
RSI and Bollinger Bands using pandas_ta. It optionally merges aggregated news features
from a CSV file (preprocessed_news_features.csv) that should contain daily sentiment
and bias scores generated by our frontend (newsMoE, finSentiment, newsBias).

The script trains an XGBoost regressor to predict the next day's return of the
closing price. It saves the trained model to models/super_model.json and the
processed dataset with target values to public/data/super_model_dataset.csv.
"""

import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import xgboost as xgb

try:
    import pandas_ta as ta
except ImportError:
    ta = None

def load_price_data(path: str) -> pd.DataFrame:
    """Load gold price data from a CSV file and sort by date."""
    df = pd.read_csv(path, parse_dates=['date'])
    df = df.sort_values('date')
    return df

def compute_technical_indicators(df: pd.DataFrame) -> pd.DataFrame:
    """Compute simple technical indicators for the gold price data."""
    if ta is None:
        raise ImportError("pandas_ta is required for technical indicators. Install via 'pip install pandas_ta'.")
    df = df.copy()
    # Simple and exponential moving averages
    df['SMA_5'] = ta.sma(df['close'], length=5)
    df['SMA_20'] = ta.sma(df['close'], length=20)
    df['EMA_5'] = ta.ema(df['close'], length=5)
    df['EMA_20'] = ta.ema(df['close'], length=20)
    # Relative Strength Index
    df['RSI_14'] = ta.rsi(df['close'], length=14)
    # Bollinger Bands (lower, middle, upper)
    bbands = ta.bbands(df['close'], length=20, std=2)
    df['BBL_20'] = bbands['BBL_20_2.0']
    df['BBM_20'] = bbands['BBM_20_2.0']
    df['BBU_20'] = bbands['BBU_20_2.0']
    # Daily returns
    df['return_1d'] = df['close'].pct_change()
    return df

def merge_news_features(price_df: pd.DataFrame, news_path: str) -> pd.DataFrame:
    """Merge aggregated news features with the price data on the date column."""
    if news_path and os.path.exists(news_path):
        news_df = pd.read_csv(news_path, parse_dates=['date'])
        merged = price_df.merge(news_df, on='date', how='left')
    else:
        merged = price_df.copy()
    return merged

def prepare_dataset(df: pd.DataFrame):
    """Prepare feature matrix X and target vector y from the merged dataframe."""
    df = df.dropna().copy()
    df['target'] = df['return_1d'].shift(-1)
    df = df.dropna()
    X = df.drop(columns=['date', 'target'])
    y = df['target']
    return X, y, df[['date', 'target']]

def train_super_model(price_path: str = 'public/data/xauusd_ohlc_clean.csv',
                      news_features_path: str = 'public/data/preprocessed_news_features.csv',
                      output_dataset: str = 'public/data/super_model_dataset.csv',
                      model_output_dir: str = 'models') -> None:
    """Train the super model using price data and optionally news features."""
    price_df = load_price_data(price_path)
    price_df = compute_technical_indicators(price_df)
    merged_df = merge_news_features(price_df, news_features_path)
    X, y, processed_df = prepare_dataset(merged_df)
    # Use time-series split: do not shuffle
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)
    model = xgb.XGBRegressor(
        n_estimators=300,
        max_depth=6,
        learning_rate=0.05,
        subsample=0.8,
        colsample_bytree=0.8,
        objective='reg:squarederror',
        random_state=42
    )
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    mse = mean_squared_error(y_test, preds)
    r2 = r2_score(y_test, preds)
    print(f"Test MSE: {mse:.6f}, R2: {r2:.4f}")
    # Save processed dataset and model
    os.makedirs(model_output_dir, exist_ok=True)
    processed_df.to_csv(output_dataset, index=False)
    model.save_model(os.path.join(model_output_dir, 'super_model.json'))
    print(f"Super model saved to {os.path.join(model_output_dir, 'super_model.json')} and dataset to {output_dataset}")

if __name__ == '__main__':
    train_super_model()
